---
title: "Hands-on Exercise 1: Geospatial Data Wrangling  with R"
author: "Hulwana"
editor: visual
---

# 1 Geospatial Data Wrangling

In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages.

## 1.1 Getting Started

The code chunk below install and load the following packages into R environment.

-   [**sf**](https://r-spatial.github.io/sf/) : for importing, managing and processing geospatial data

-   [**tidyverse**](https://www.tidyverse.org/) : for data preparation such as importing, wrangling and visualizing data

-   [**tmap**](https://cran.r-project.org/web/packages/tmap/): for creating thematic maps

```{r}
pacman::p_load(sf, tmap, tidyverse)
```

## 1.2 Importing Geospatial Data

Unlike general data saved in excel or csv, geospatial data has to be read by the *st_read()* function of the **sf** package to capture the polygon feature. An example of importing geospatial data is as shown below.

### 1.2.1 Importing polygon feature data in shapefile format

```{r}
mpsz <- st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

The above message indicates that the geospatial data consists of 323 multipolygon features and 15 fields.

### 1.2.2 Importing polyline feature data in shapefile form

The code chunk below uses *st_read()* function of **sf** package to import `CyclingPath` shapefile into R as line feature data frame.

```{r}
cyclingpath <- st_read(dsn = "data/geospatial", 
                         layer = "CyclingPath")
```

The above message reveals that there are a total of 1625 Linestring features and 2 fields in 'CyclingPath' and it is in svy21 projected coordinates system too.

### 1.2.3 Importing GIS data in kml format

As the `pre-schools-location-kml` is in kml format, the syntax for importing the data differs slightly.

```{r}
preschool <- st_read("data/geospatial/pre-schools-location-kml.kml")
```

## 1.3 Viewing the data frame

In this sub-section, we will retrieve information related to the content of a simple feature data frame.

### 1.3.1 Working with *st_geometry()*

The column in the sf data.frame that contains the geometries is a list, of class `sfc`. We can retrieve the geometry list-column in this case by mpsz\$geom or mpsz\[\[1\]\], but the more general way uses *st_geometry()* as shown in the code chunk below.

```{r}
st_geometry(mpsz)
```

However, the *st_geometry()* function only provides basic geospatial information such as the number of features and the geometric type for which in this case it is a multipolygon.

### **1.3.2 Working with *glimpse()***

To get an overview on other non-geospatial data we will use *glimpse()*.

```{r}
glimpse(mpsz)
```

From the above output, we have a glimpse of the fields available in the dataset and their respective data type. For example 'OBJECTID' and 'SUBZONE_NO' are both **integer** data type whereas `X_ADDR`, `Y_ADDR`, `SHAPE_L` and `SHAPE_AREA` fields are all in **double-precision values**.

**1.3.3 Working with *head()***

To view the first 5 observations, we can use the function *head()*. By default, it will show the first 6 observations. To view a specific number of observation based on the top of the data table, it can be specified in the function by the code "n=5".

```{r}
head(mpsz, n = 5)
```

## 1.4 Plotting the Geospatial Data

### 1.4.1 Overview plot

To visualize geospatial data, we will use the function *plot()*.

```{r}
plot(mpsz)
```

The above plot showcases a multi-plot of all attributes.

### 1.4.2 Plot Geometry Only

To get the main geometry, we can run the st_geometry() function within the plot() function.

```{r}
plot(st_geometry(mpsz))
```

### 1.4.3 Plot for a Particular Attribute

We can also choose to plot the sf object based on a specific attribute by indicating the attribute into the code chunk as shown:

```{r}
plot(mpsz["PLN_AREA_N"])
```

## 1.5 Working with Projection

Map projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.

In this section we will perform projection transformation in which a simple feature data frame will be projected from one coordinate system to another coordinate system.

### 1.5.1 Assigning EPSG code to a simple feature data frame

One of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.

This is an example the coordinate system of `mpsz` simple feature data frame by using *st_crs()* of *sf* package as shown in the code chunk below.

```{r}
st_crs(mpsz)
```

Although `mpsz` data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be [3414](https://epsg.io/3414).

In order to assign the correct EPSG code to `mpsz` data frame, *st_set_crs()* of **sf** package is used as shown in the code chunk below.

```{r}
mpsz3414 <- st_set_crs(mpsz, 3414)
```

Now, let us check the CSR again by using the code chunk below:

```{r}
st_crs(mpsz3414)
```

The ESPG code has been updated to 3414.

### 1.5.2 Transforming the projection of preschool from wgs84 to svy21

In geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.

Let us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.

```{r}
st_geometry(preschool)
```

This is a scenario that *st_set_crs()* is not appropriate and *st_transform()* of sf package should be used. This is because we need to reproject `preschool` from one coordinate system to another coordinate system mathemetically.

Let us perform the projection transformation by using the code chunk below.

```{r}
preschool3414 <- st_transform(preschool, crs = 3414)
```

Next, let us display the content of preschool3414 sf data frame as shown below.

```{r}
st_geometry(preschool3414)
```

Notice that it is in svy21 projected coordinate system now. Furthermore, if you refer to *Bounding box:*, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.

## 1.6 Importing and Converting An Aspatial Data

In practice, it is not unusual that we will come across data such as `listing` of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.

In this section, you will learn how to import an aspatial data into R environment and save it as a tibble data frame. Next, you will convert it into a simple feature data frame.

For the purpose of this exercise, the `listings.csv` data downloaded from AirBnb will be used.

### 1.6.1 Importing the Aspatial Data

Since `listings` data set is in csv file format, we will use [*read_csv()*](https://readr.tidyverse.org/reference/read_delim.html) of **readr** package to import `listing.csv` as shown the code chunk below. The output R object is called `listings` and it is a [tibble data frame](https://r4ds.had.co.nz/tibbles.html).

```{r}
listings <- read_csv("data/aspatial/listings.csv")
```

The output reveals that `listing` tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are `latitude` and `longitude`. Note that they are in decimal degree format. As a best guess, we will assume that the data is in **wgs84** Geographic Coordinate System.

### 1.6.2 Creating a simple feature data frame from an aspatial data frame

The code chunk below converts `listing` data frame into a simple feature data frame by using [*st_as_sf()*](https://r-spatial.github.io/sf/reference/st_as_sf.html) of **sf** packages

```{r}
listings_sf <- st_as_sf(listings, 
                       coords = c("longitude", "latitude"),
                       crs=4326) %>%
  st_transform(crs = 3414)
```

Things to learn from the arguments above:

-   *coords* argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.

-   *crs* argument requires you to provide the coordinates system in epsg format. [EPSG: 4326](https://epsg.io/4326) is wgs84 Geographic Coordinate System and [EPSG: 3414](https://epsg.io/3414) is Singapore SVY21 Projected Coordinate System. You can search for other country\'s epsg code by referring to [epsg.io](https://epsg.io/).

-   *%\>%* is used to nest *st_transform()* to transform the newly created simple feature data frame into svy21 projected coordinates system.

Let us examine the content of this newly created simple feature data frame.

```{r}
glimpse(listings_sf)
```

Table above shows the content of `listing_sf`. Notice that a new column called `geometry` has been added into the data frame. On the other hand, the `longitude` and `latitude` columns have been dropped from the data frame.

## 1.7 Geoprocessing with sf package

Besides providing functions to handling (i.e.Â importing, exporting, assigning projection, transforming projection etc) geospatial data, **sf** package also offers a wide range of geoprocessing (also known as GIS analysis) functions.

In this section, you will learn how to perform two commonly used geoprocessing functions, namely [buffering](https://www.gislounge.com/buffers-in-gis/) and point in polygon count.

### 1.7.1 Buffering

The scenario:

The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.

The solution:

Firstly, [*st_buffer()*](https://r-spatial.github.io/sf/reference/geos_unary.html) of **sf** package is used to compute the 5-meter buffers around cycling paths

```{r}
buffer_cycling <- st_buffer(cyclingpath, 
                               dist=5, nQuadSegs = 30)
```

This is followed by calculating the area of the buffers as shown in the code chunk below.

```{r}
buffer_cycling$AREA <- st_area(buffer_cycling)
```

Lastly, sum() of Base R will be used to derive the total land involved

```{r}
sum(buffer_cycling$AREA)
```

### 1.7.2 Point-in-polygon count

The scenario:

A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.

The solution:

The code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using [st_intersects()](https://r-spatial.github.io/sf/reference/geos_binary_pred.html). Next, [*length()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/length) of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.

```{r}
mpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))
```

You can check the summary statistics of the newly derived *PreSch Count* field by using *summary()* as shown in the code chunk below.

```{r}
summary(mpsz3414$`PreSch Count`)
```

To list the planning subzone with the most number of pre-school, the [*top_n()*](https://dplyr.tidyverse.org/reference/top_n.html) of **dplyr** package is used as shown in the code chunk below.

```{r}
top_n(mpsz3414, 1, `PreSch Count`)
```

The solution:

Firstly, the code chunk below uses [*st_area()*](https://r-spatial.github.io/sf/reference/geos_measures.html) of **sf** package to derive the area of each planning subzone.

```{r}
mpsz3414$Area <- mpsz3414 %>% st_area()
```

Next, [*mutate()*](https://dplyr.tidyverse.org/reference/mutate.html) of [**dplyr**](https://dplyr.tidyverse.org/) package is used to compute the density by using the code chunk below.

```{r}
mpsz3414 <- mpsz3414 %>%
  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)
```

## 1.8 Exploratory Data Analysis

In practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate [ggplot2](https://ggplot2.tidyverse.org/) functions to create functional and yet truthful statistical graphs for EDA purposes.

### 1.8.1 Histogram to View Overall Distribution for Numeric Fields

Firstly, we will plot a histogram to reveal the distribution of `PreSch Density`. Conventionally, *hist()* of R Graphics will be used as shown in the code chunk below.

```{r}
hist(mpsz3414$`PreSch Density`)
```

Although the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.

In the code chunk below, appropriate **ggplot2** functions will be used.

```{r}
ggplot(data=mpsz3414, 
       aes(x= as.numeric(`PreSch Density`)))+
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  labs(title = "Are pre-school even distributed in Singapore?",
       subtitle= "There are many planning sub-zones with a single pre-school, on the other hand, \nthere are two planning sub-zones with at least 20 pre-schools",
      x = "Pre-school density (per km sq)",
      y = "Frequency")
```

### 
1.8.2 Scatterplot to see the relationship between 2 continuous data

The solution:

```{r}
ggplot(data=mpsz3414, 
       aes(x= as.numeric(`PreSch Density`), y =as.numeric(`PreSch Count`)))+
  geom_point() +
  labs(x = "Pre-school density (per km sq)",
      y = "Pre-school count")
```

# 
2 Choropleth Mapping

Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.

## 2.1 Importing Attribute Data

Next, we will import *respopagsex2000to2018.csv* file into RStudio and save the file into an R dataframe called *popagsex*.

The task will be performed by using *read_csv()* function of **readr** package as shown in the code chunk below.

```{r}
popdata <- read_csv("data/aspatial/respopagesextod2011to2020.csv")
```

## 2.2 Data Preparation 

Before a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.

-   YOUNG: age group 0 to 4 until age groyup 20 to 24,

-   ECONOMY ACTIVE: age group 25-29 until age group 60-64,

-   AGED: age group 65 and above,

-   TOTAL: all age group, and

-   DEPENDENCY: the ratio between young and aged against economy active group

### 2.2.1 Data Wrangling

The following data wrangling and transformation functions will be used:

-   *pivot_wider()* of **tidyr** package, and

-   *mutate()*, *filter()*, *group_by()* and *select()* of **dplyr** package

```{r}
popdata2020 <- popdata %>%
  filter(Time == 2020) %>%
  group_by(PA, SZ, AG) %>%
  summarise(`POP` = sum(`Pop`)) %>%
  ungroup()%>%
  pivot_wider(names_from=AG, 
              values_from=POP) %>%
  mutate(YOUNG = rowSums(.[3:6])
         +rowSums(.[12])) %>%
mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+
rowSums(.[13:15]))%>%
mutate(`AGED`=rowSums(.[16:21])) %>%
mutate(`TOTAL`=rowSums(.[3:21])) %>%  
mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)
/`ECONOMY ACTIVE`) %>%
  select(`PA`, `SZ`, `YOUNG`, 
       `ECONOMY ACTIVE`, `AGED`, 
       `TOTAL`, `DEPENDENCY`)
```

### 2.2.2 Joining the attribute data and geospatial data

Before we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.

```{r}
popdata2020 <- popdata2020 %>%
  mutate_at(.vars = vars(PA, SZ), 
          .funs = funs(toupper)) %>%
  filter(`ECONOMY ACTIVE` > 0)
```

Thing to learn from the code chunk above:

-   *left_join()* of **dplyr** package is used with `mpsz` simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.

```{r}
#write_rds(mpsz_pop2020, "data/rds/mpszpop2020.rds")
mpsz_pop2020 <- read_rds("data/rds/mpszpop2020.rds")
```

## 2.3 Visualising Choropleth

Two approaches can be used to prepare thematic map using *tmap*, they are:

-   Plotting a thematic map quickly by using *qtm()*.

-   Plotting highly customisable thematic map by using tmap elements.

### 2.3.1 Plot using qtm()

The easiest and quickest to draw a choropleth map using **tmap** is using *qtm()*. It is concise and provides a good default visualisation in many cases.

The code chunk below will draw a cartographic standard choropleth map as shown below.

```{r}
tmap_mode("plot")
qtm(mpsz_pop2020, 
    fill = "DEPENDENCY")
```

Things to learn from the code chunk above:

-   *tmap_mode()* with \"plot\" option is used to produce a static map. For interactive mode, \"view\" option should be used.

-   *fill* argument is used to map the attribute (i.e.Â DEPENDENCY)

### 2.3.2 Plot using tmap's elements

Despite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of *qtm()* is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, **tmap**\'s drawing elements should be used.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues",
          title = "Dependency ratio") +
  tm_layout(main.title = "Distribution of Dependency Ratio by planning subzone",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\n and Population data from Department of Statistics DOS", 
             position = c("left", "bottom"))
```

#### 2.3.2.1 Drawing a base map

The basic building block of **tmap** is *tm_shape()* followed by one or more layer elemments such as *tm_fill()* and *tm_polygons()*.

In the code chunk below, *tm_shape()* is used to define the input data (i.e *mpsz_pop2020*) and *tm_polygons()* is used to draw the planning subzone polygons.

```{r}
tm_shape(mpsz_pop2020) +
  tm_polygons()
```

#### 2.3.2.2 Drawing a choropleth map using *tm_polygons()*

To draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as *Dependency* to *tm_polygons()*.

```{r}
tm_shape(mpsz_pop2020)+
  tm_polygons("DEPENDENCY")
```

Things to learn from *tm_polygons()*:

-   The default interval binning used to draw the choropleth map is called \"pretty\". A detailed discussion of the data classification methods supported by **tmap** will be provided in sub-section 4.3.

-   The default colour scheme used is `YlOrRd` of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.

-   By default, Missing value will be shaded in grey.

2.3.2.3 Drawing a choropleth map using *tm_fill()* and \*\*tm_border()\*\*

Actually, *tm_polygons()* is a wraper of *tm_fill()* and *tm_border()*. *tm_fill()* shades the polygons by using the default colour scheme and *tm_borders()* adds the borders of the shapefile onto the choropleth map.

The code chunk below draws a choropleth map by using *tm_fill()* alone.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY")
```

Notice that the planning subzones are shared according to the respective dependecy values

To add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY") +
  tm_borders(lwd = 0.1,  alpha = 1)
```

Notice that light-gray border lines have been added on the choropleth map.

The *alpha* argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).

Beside *alpha* argument, there are three other arguments for *tm_borders()*, they are:

-   *col* = border colour,

-   *lwd* = border line width. The default is 1, and

-   *lty* = border line type. The default is \"solid\".

## 






